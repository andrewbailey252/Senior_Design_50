{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOFQqyCwQ7Iw4/SNG02VCsR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Machine Learning For Power Dissagregation"],"metadata":{"id":"pt6jM_emhemt"}},{"cell_type":"markdown","source":["### Import Libraries\n"],"metadata":{"id":"UmLWRr76WeWq"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.tree import DecisionTreeRegressor"],"metadata":{"id":"MEstAyUCWiKO","executionInfo":{"status":"ok","timestamp":1701294104984,"user_tz":300,"elapsed":12368,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### Mount Drive"],"metadata":{"id":"aqvO0y02WjbB"}},{"cell_type":"code","source":["# Mount Google Drive (if using Colab)\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRUYDOIqWjCd","executionInfo":{"status":"ok","timestamp":1701294127356,"user_tz":300,"elapsed":22382,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}},"outputId":"f7cc5103-5b4c-4362-8a53-db233fa5c4cc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Load Data & preprocess time"],"metadata":{"id":"R_u31dtyWqIP"}},{"cell_type":"code","source":["# List of CSV files to use for training\n","csv_files = ['/content/drive/MyDrive/50_ResidentialPowerDisaggregation_SD_Fall23/1.2 Software/Colab Notebooks/ML Models/Andrew/MLData_long.csv']  # Add more file names as needed\n","\n","# Load and concatenate data from multiple CSV files\n","data_list = []\n","for csv_file in csv_files:\n","    data = pd.read_csv(csv_file)\n","    data_list.append(data)\n","\n","# Concatenate data from all CSV files\n","data = pd.concat(data_list, ignore_index=True)\n","\n","# Preprocess the timestamp column to extract relevant information\n","data['timestamp'] = pd.to_datetime(data['timestamp'])\n","data['Hour'] = data['timestamp'].dt.hour\n","data['DayOfWeek'] = data['timestamp'].dt.dayofweek\n","data['Month'] = data['timestamp'].dt.month\n","\n","# Remove negative values for appropriate columns\n","for column in data.columns:\n","    if column != 'timestamp':\n","        data[column] = data[column].clip(lower=0)  # Clip negative values\n","\n","# Remove rows with null values\n","data = data.dropna()"],"metadata":{"id":"AcPH55mYWpL_","executionInfo":{"status":"ok","timestamp":1701294129129,"user_tz":300,"elapsed":1784,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Features, split, and sequences"],"metadata":{"id":"a_rnEk3FWx1p"}},{"cell_type":"code","source":["# Define features and targets\n","X = data[['Hour', 'DayOfWeek', 'Month', 'Total']]\n","y = data[['Washer', 'BlowerGH', 'Lights', 'BlowerBed', 'CompGH', 'CompBed', 'Dryer', 'Recs1', 'Recs2', 'WaterHeater']]\n","\n","# Normalize features and targets\n","scaler_X = MinMaxScaler()\n","X = scaler_X.fit_transform(X)\n","\n","scaler_y = MinMaxScaler()\n","y = scaler_y.fit_transform(y)\n","\n","# Function to create sequences\n","def create_dataset(X, y, time_steps=1):\n","    Xs, ys = [], []\n","    for i in range(len(X) - time_steps + 1):\n","        v = X[i:(i + time_steps)]\n","        Xs.append(v)\n","        ys.append(y[i + time_steps - 1])\n","    return np.array(Xs), np.array(ys)\n","\n","TIME_STEPS = 10\n","\n","# Create sequences\n","X_seq, y_seq = create_dataset(X, y, TIME_STEPS)\n","\n","# Split data into training and testing\n","split_ratio = 0.80\n","split_index = int(len(X_seq) * split_ratio)\n","\n","X_train, y_train = X_seq[:split_index], y_seq[:split_index]\n","X_test, y_test = X_seq[split_index:], y_seq[split_index:]"],"metadata":{"id":"K-LtNiUYW4m1","executionInfo":{"status":"ok","timestamp":1701294129131,"user_tz":300,"elapsed":11,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Machine Learning Models"],"metadata":{"id":"UFMGt3njgaFh"}},{"cell_type":"markdown","source":["### CNN model"],"metadata":{"id":"Dlk45Tc2W_iK"}},{"cell_type":"code","source":["# Define a function to create the CNN-LSTM model\n","def create_cnn_lstm_model(input_shape):\n","    model = Sequential()\n","    # Add convolutional layers\n","    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape))\n","    model.add(MaxPooling1D(pool_size=2))\n","    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n","    model.add(MaxPooling1D(pool_size=2))\n","    # Reshape the data for LSTM\n","    model.add(tf.keras.layers.Reshape((-1, 64)))  # 64 corresponds to the number of filters in the last Conv1D layer\n","    # Add LSTM layers\n","    model.add(LSTM(50, return_sequences=True))\n","    model.add(LSTM(50))\n","    # Add dense layers\n","    model.add(Dense(10))  # This 10 corresponds to the number of output features\n","    model.compile(optimizer='adam', loss='mse')\n","    return model\n","\n","# Create and compile the CNN-LSTM model\n","cnn_lstm_model = create_cnn_lstm_model((X_train.shape[1], X_train.shape[2]))\n","\n","# Train the CNN-LSTM model on your data\n","cnn_lstm_model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftjlemxtXAxm","executionInfo":{"status":"ok","timestamp":1701294180316,"user_tz":300,"elapsed":51194,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}},"outputId":"828f642f-7b70-486f-a705-35c268e94f9d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","288/288 [==============================] - 13s 12ms/step - loss: 0.0368 - val_loss: 0.0074\n","Epoch 2/10\n","288/288 [==============================] - 2s 6ms/step - loss: 0.0269 - val_loss: 0.0071\n","Epoch 3/10\n","288/288 [==============================] - 3s 10ms/step - loss: 0.0242 - val_loss: 0.0073\n","Epoch 4/10\n","288/288 [==============================] - 3s 12ms/step - loss: 0.0224 - val_loss: 0.0076\n","Epoch 5/10\n","288/288 [==============================] - 3s 10ms/step - loss: 0.0214 - val_loss: 0.0072\n","Epoch 6/10\n","288/288 [==============================] - 2s 7ms/step - loss: 0.0206 - val_loss: 0.0076\n","Epoch 7/10\n","288/288 [==============================] - 2s 7ms/step - loss: 0.0197 - val_loss: 0.0069\n","Epoch 8/10\n","288/288 [==============================] - 4s 13ms/step - loss: 0.0188 - val_loss: 0.0077\n","Epoch 9/10\n","288/288 [==============================] - 2s 8ms/step - loss: 0.0181 - val_loss: 0.0069\n","Epoch 10/10\n","288/288 [==============================] - 3s 11ms/step - loss: 0.0173 - val_loss: 0.0068\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7f1e745ead10>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### Random Forest Model"],"metadata":{"id":"bGMYJcyAXHhD"}},{"cell_type":"code","source":["# Define function to create the Random Forest model\n","def create_random_forest_model():\n","    model = RandomForestRegressor(n_estimators=100, random_state=42)  #Adjust the number of estimators as needed\n","    return model\n","\n","# Create Random Forest model\n","random_forest_model = create_random_forest_model()\n","\n","# Train the Random Forest model on data\n","# Reshape X_train and X_test to 2D arrays\n","X_train_rf = X_train.reshape(X_train.shape[0], -1)\n","X_test_rf = X_test.reshape(X_test.shape[0], -1)\n","\n","random_forest_model.fit(X_train_rf, y_train)  # Train the Random Forest model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"nb5K6APEXJME","executionInfo":{"status":"ok","timestamp":1701294190450,"user_tz":300,"elapsed":10170,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}},"outputId":"b09f6a57-58ca-4712-e666-a8e4d68b375f"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor(random_state=42)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### Decision Trees model"],"metadata":{"id":"gV7-D6YAXTki"}},{"cell_type":"code","source":["# Define a function to create the Decision Trees model\n","def create_decision_trees_model():\n","    model = DecisionTreeRegressor(random_state=42)\n","    return model\n","\n","# Create the Decision Trees model\n","decision_trees_model = create_decision_trees_model()\n","\n","# Train the Decision Trees model on your data\n","decision_trees_model.fit(X_train_rf, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"qbn2s9cPXNyY","executionInfo":{"status":"ok","timestamp":1701294190452,"user_tz":300,"elapsed":33,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}},"outputId":"d4aca06b-1ce5-4ae0-e86e-ccb09794f1ec"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeRegressor(random_state=42)"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=42)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### Making Predictions"],"metadata":{"id":"Z_GWEHMuXodK"}},{"cell_type":"code","source":["# Make predictions using all three models\n","cnn_lstm_predictions = cnn_lstm_model.predict(X_test)\n","X_test_rf = X_test.reshape(X_test.shape[0], -1)  # Reshape X_test for Random Forest and Decision Trees\n","random_forest_predictions = random_forest_model.predict(X_test_rf)  # Predict with Random Forest\n","decision_trees_predictions = decision_trees_model.predict(X_test_rf)  # Predict with Decision Trees\n","\n","# Inverse transform the CNN-LSTM predictions and actual values to get them back in Watts\n","cnn_lstm_predicted_values = scaler_y.inverse_transform(cnn_lstm_predictions)\n","cnn_lstm_actual_values = scaler_y.inverse_transform(y_test)\n","\n","# Inverse transform the Random Forest predictions\n","random_forest_predicted_values = scaler_y.inverse_transform(random_forest_predictions)\n","\n","# Inverse transform the Decision Trees predictions\n","decision_trees_predicted_values = scaler_y.inverse_transform(decision_trees_predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ypexTeEXpjG","executionInfo":{"status":"ok","timestamp":1701294191771,"user_tz":300,"elapsed":1339,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}},"outputId":"dc702be6-13d6-411e-ec2c-d6386e69d027"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["36/36 [==============================] - 1s 3ms/step\n"]}]},{"cell_type":"markdown","source":["### Testing and plotting each model"],"metadata":{"id":"c9o3lbAkXcmk"}},{"cell_type":"code","source":["# Extract timestamps for test\n","test_timestamps = data['timestamp'].iloc[-len(X_test):]\n","\n","appliance_names = ['Washer', 'BlowerGH', 'Lights', 'BlowerBed', 'CompGH', 'CompBed', 'Dryer', 'Recs1', 'Recs2', 'WaterHeater']\n","\n","# Create an empty DataFrame to store the results for all models\n","results_df = pd.DataFrame(columns=['Model', 'Appliance', 'Actual Total (Watts)', 'Predicted Total (Watts)', 'MAPE', 'RMSE', 'MAE'])\n","\n","# List of model names\n","model_names = ['CNN-LSTM', 'Random Forest', 'Decision Trees']\n","\n","# List of models\n","models = [cnn_lstm_model, random_forest_model, decision_trees_model]\n","\n","# Loop through each model\n","for model_name, model in zip(model_names, models):\n","    if model_name == 'Random Forest' or model_name == 'Decision Trees':\n","        predictions = model.predict(X_test_rf)  # Use reshaped data for Random Forest and Decision Trees\n","    else:\n","        predictions = model.predict(X_test)  # Use original data for CNN-LSTM\n","\n","    # Inverse transform the predictions and actual values to get them back in Watts\n","    predicted_values = scaler_y.inverse_transform(predictions)\n","    actual_values = scaler_y.inverse_transform(y_test)\n","\n","    # Create an empty DataFrame to store the results for the current model\n","    model_results_df = pd.DataFrame(columns=['Appliance', 'Actual Total (Watts)', 'Predicted Total (Watts)', 'MAPE', 'RMSE', 'MAE'])\n","\n","    for idx, appliance in enumerate(appliance_names):\n","        plt.figure(figsize=(15, 7))\n","\n","        # Plot actual usage\n","        plt.plot(test_timestamps, actual_values[:, idx], label='Actual', color='C' + str(idx))\n","\n","        # Plot predicted usage\n","        plt.plot(test_timestamps, predicted_values[:, idx], label='Predicted', color='C' + str(idx + 7))\n","\n","        plt.title(f\"{model_name} - {appliance} - Actual vs Predicted\")\n","        plt.xlabel('Timestamp')\n","        plt.ylabel('Power Consumption (Watts)')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.xticks(rotation=45)\n","        plt.tight_layout()\n","        plt.show()\n","\n","        # Calculate actual and predicted total power in watts for the current appliance\n","        actual_total = actual_values[:, idx].sum()\n","        predicted_total = predicted_values[:, idx].sum()\n","\n","        # Calculate the Mean Absolute Percentage Error (MAPE) for the current appliance\n","        #The code below calculates error at each point which is causing issues\n","        absolute_percentage_error = np.abs((actual_values[:, idx] - predicted_values[:, idx]) / actual_values[:, idx])\n","        mape = np.mean(absolute_percentage_error) * 100\n","\n","        # Mean Absolute Percentage Error (MAPE) at lower resolution\n","\n","        # Define block size (testing 15 minutes of resolution)\n","        block_size = 15\n","\n","        # Calculate the number of complete blocks - cant have an incomplete one\n","        num_complete_blocks = len(actual_values) // block_size\n","\n","        # Trim arrays to only include complete blocks\n","        trimmed_actual_values = actual_values[:num_complete_blocks * block_size,idx]\n","        trimmed_predicted_values = predicted_values[:num_complete_blocks * block_size,idx]\n","\n","        # Reshape and aggregate the data\n","        actual_agg = np.sum(trimmed_actual_values.reshape(-1, block_size), axis=1)\n","        predicted_agg = np.sum(trimmed_predicted_values.reshape(-1, block_size), axis=1)\n","\n","        # Calculate the absolute percentage error for each aggregated block\n","        absolute_percentage_error_agg = np.abs((actual_agg - predicted_agg) / actual_agg)\n","\n","        # Calculate MAPE (at block resoluition)\n","        mape_agg = np.mean(absolute_percentage_error_agg) * 100\n","\n","\n","        # Calculate the Root Mean Square Error (RMSE) for the current appliance\n","        rmse = np.sqrt(np.mean((actual_values[:, idx] - predicted_values[:, idx]) ** 2))\n","\n","        # Calculate the Mean Absolute Error (MAE) for the current appliance\n","        mae = np.mean(np.abs(actual_values[:, idx] - predicted_values[:, idx]))\n","\n","        # Append the results to the DataFrame for the current model\n","        model_results_df = model_results_df.append({'Appliance': appliance,\n","                                                    'Actual Total (Watts)': actual_total,\n","                                                    'Predicted Total (Watts)': predicted_total,\n","                                                    'MAPE': mape,\n","                                                    'RMSE': rmse,\n","                                                    'MAE': mae,\n","                                                    'MAPE Agg': mape_agg},\n","                                                   ignore_index=True)\n","\n","    # Calculate and display the overall total power usage comparison\n","    actual_total_combined = actual_values.sum(axis=1).sum()\n","    predicted_total_combined = predicted_values.sum(axis=1).sum()\n","\n","    print(f\"Total Power Usage for All Appliances Combined (Actual): {actual_total_combined:.2f} Watts\")\n","    print(f\"Total Power Usage for All Appliances Combined (Predicted): {predicted_total_combined:.2f} Watts\")\n","    print(f\"Percentage Error for All Appliances Combined: {((actual_total_combined - predicted_total_combined) / actual_total_combined) * 100:.2f}%\")\n","    print()\n","\n","    # Append the results for the current model to the overall results DataFrame\n","    model_results_df['Model'] = model_name\n","    results_df = pd.concat([results_df, model_results_df])\n","\n","# Display the results DataFrame for all models\n","print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"14pAO2SgVidr6J-kDR0AUHyfvvu_5RwNU"},"id":"0Ygm3TuGXk_5","executionInfo":{"status":"ok","timestamp":1701294221418,"user_tz":300,"elapsed":29670,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}},"outputId":"e856b219-90e9-42a0-b9d4-67de5795aab4"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["#### Export Error Values Calculated to CSV"],"metadata":{"id":"YGNIkXLbk83p"}},{"cell_type":"code","source":["results_df.to_csv('error_values.csv', index=False)"],"metadata":{"id":"QbWgDGYakrz4","executionInfo":{"status":"ok","timestamp":1701294221419,"user_tz":300,"elapsed":37,"user":{"displayName":"Andrew Bailey","userId":"14671441464794503327"}}},"execution_count":10,"outputs":[]}]}